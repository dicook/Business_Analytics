<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Predicting How Points End in Tennis</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Jacqueline Vella   Arunabh Banerjee   Weihao Li   Shayne D’Lima   David Cai" />
    <link href="libs/remark-css/shinobi.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Predicting How Points End in Tennis
## ETC3250 Project
### <br> Jacqueline Vella <br> Arunabh Banerjee <br> Weihao Li <br> Shayne D’Lima <br> David Cai

---




# Feature Engineering

#### Distance and Positioning
  - Position of winners when making final or penultimate shot
  - Position of losers when they made or recieved the final shot
  - Distance travelled, distance from the centre line and depth of point winners and losers
  - Distance of winners and losers from the centre line
 
&lt;div style= "float:right;position: relative; top: -100px;"&gt;

&lt;img src="Features.png" width="600px" style="display: block; margin: auto;" /&gt;

&lt;/div&gt;
#### Shot composition
  - Whether the set-up for the final shot based on the penultimate shot affected the outcome
  - Differences in shot speed, net clearance, and ball bounce position
  - Time to set up shot based on previous shot trajectory

#### Winning Shot
  - How the winner won the shot
  - If a server won the point, the number of shots in a rally can determine whether they hit a winner or the opponent made an error
  - Distance covered by a non-server when they made an error

---


# Model Methodology

&lt;div style= "float:right;position: relative; top: 50px;"&gt;
&lt;img src="Diagnostics.png" width="400px" style="display: block; margin: auto;" /&gt;
&lt;/div&gt;

### Preliminary XGBoost
Application
- 10 fold cross validation for reasonable bias and variance
- Multi:softprobe - helpful for problematic cases
- Milticlass logloss evaluation metric - characterises error as the uncertainty in our classifiers
- Other choices for model were; nrounds = 200, eta = 0.05, gamma = 0
- Found the best iterations, in terms of mlogloss, for each folds and created a best xgBM model for them
- Then determined variable importance and training and test accuracy

Diagnostics
- Divergence around 40 iterations
- Likely minimised over fitting - test loss is minimal and relatively close to training error
- Optimal iteration around 160


---

&lt;div style= "float:right;position: relative; top: 0px;"&gt;
&lt;img src="oob.png" width="400px" style="display: block; margin: auto;" /&gt;&lt;img src="Stacked NN.png" width="400px" style="display: block; margin: auto;" /&gt;
&lt;/div&gt;
### Bagging Neural Networks 
- 5k - 30k trainable parameters
- 0.2-0.5 dropout rate   &amp;   batch normalization
- Activation Function: ReLu or LeakyReLu. SoftMax for output layer.
  - No activation function for first hidden layer
- 300 - 2000 epochs 
- 10 - 30 Neural Networks with random hyper parameters to build a vote matrix
  - Don't need to use cross validation (save time)
  
### Stacked Neural Networks
- 9% data: sub models (Neural Networks)
- 81% data: meta-learner (Neural Networks)
- use raw inputs and prediction of sub models as the inputs of meta-learner
- cross validation for meta-learner

### Ensemble XGBoost and RF
- Created different models
- Tuned parameters and changed some to be more suitable to data
- Utilised inbuilt xgb cross validation
- Created an ensemble with the use of weighted averages
- Provided different weights to models to optimise test set and choose the model that maximsed test accuracy

---

# Results


&lt;img src="Results.png" width="700px" style="display: block; margin: auto;" /&gt;


- Neural network performed better in public leaderboard and XGBoost performed better in private leaderboard
- Neural networks may have been susceptible to overfitting and over-parametrization
- Methods do not use the same inputs, utilised different parameters

Random Forest:
- Extremely flexible and high accuracy
- Requires considerable tuning for an optimal forest
- Overfitting easily occurred

XGBoost:
- Decrease speed of optimizing
- Prevents overfitting
- Greater test accuracy
- Considerable scope for improvement within the model


---
&lt;div style= "float:right;position: relative; top: 30px;"&gt;
&lt;img src="All feature importances.png" width="500px" style="display: block; margin: auto;" /&gt;
&lt;/div&gt;
Neural Networks:
- Speed of improvement in accuracy is faster when data is larger
- Able to get higher accuracy
- Complex system
- Easy to cause overfitting
- Each execution takes considerable time

Features:
- Errors in the most important new feature
- Can distinguish winner well but cannot distinguish unforced and forced error well
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
