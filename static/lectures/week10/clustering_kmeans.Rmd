---
title: "ETC3250: k-means clustering"
subtitle: "Semester 1, 2019"
author: "<br> Professor Di Cook <br> <br> Econometrics and Business Statistics <br> Monash University"
date: "Week 10 (a)"
output: 
  xaringan::moon_reader:
    css: ["kunoichi", "ninjutsu", "mystyle.css", "libs/animate.css"]
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
header-includes:
  - \usepackage{xcolor}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(tidy = FALSE, 
                      message = FALSE,
                      warning = FALSE,
                      echo = FALSE, 
                      fig.width=8,
                      fig.height=6,
                      fig.align = "center",
                      fig.retina = 2)
options(htmltools.dir.version = FALSE)
library(magick)
```


class: split-30
layout: false

.column[.pad10px[
## Outline

- .orange[Cluster analysis]


]]
.column[.top50px[

<br>

- The aim of cluster analysis is to group cases (objects) according to their similarity on the variables. It is also often called unsupervised classification, meaning that classification is the ultimate goal, but the classes (groups) are not known ahead of time. 
- Hence the first task in cluster analysis is to construct the class information. To determine closeness we start with measuring the interpoint distances.

]]

---

class: split-30
layout: false

.column[.pad10px[
## Outline

- .orange[Cluster analysis]
    - Cluster this


]]

.column[.top50px[

```{r out.width="80%", fig.width=6}
library(tidyverse)
library(tourr)
library(gridExtra)
library(emo)
library(knitr)
library(kableExtra)

data(flea)
ggplot(data=flea) + geom_point(aes(x=tars1, y=aede1)) + theme(aspect.ratio=1) + xlab("") + ylab("")
# Add two more examples
```


]]

---

class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- .orange[k-means]


]]

.column[.top50px[

.orange[Algorithm]

This is an iterative procedure. To use it the number of clusters, $k$, must be decided first.  The stages of the iteration are:

- Initialize by either (a) partitioning the data into k groups, and compute the $k$ group means or (b) an initial set of $k$ points as the first estimate of the cluster means (seed points).
- Loop over all observations reassigning them to the group with the closest mean.
- Recompute group means.
- Iterate steps 2 and 3 until convergence.

[Thean C. Lim's blog post](https://theanlim.rbind.io/post/clustering-k-means-k-means-and-gganimate/)
]]

---
class: split-50


.column[.pad50px[

Some data `r emo::ji("cartwheel")`

```{r}
set.seed(20190512)
df <- tibble(lbl=letters[1:12], 
             x1=sample(1:10, 12, replace=TRUE),
             x2=sample(1:10, 12, replace=TRUE))
df[1:4,2] <- df[1:4,2] + 12
df[5:8,3] <- df[5:8,3] + 12
kable(df) %>%
  kable_styling("striped", position = "center", 
                row_label_position = "c", 
                font_size=24) %>%
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:3, border_right=TRUE, width="2cm") 
```
]]
.column[.pad50px[
```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=df, aes(x1, x2)) + geom_text(aes(label=lbl)) + 
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1) 
```
]]

---
class: split-50
layout: false


.column[.pad10px[.content[

```{r}
# Set the initial means, seeding the algorithm
xb <- data.frame(cl = factor(c(1, 2)), x1 = sample(1:20, 2), x2 = sample(1:20, 2))
```

Select $k=2$, and set initial seed means <br>
$\bar{x}_1=$ (`r xb[1,-1]`) ,
$\bar{x}_2=$ (`r xb[2,-1]`) <br>
Compute distances $(d_1, d_2)$ between each observation and each mean.

```{r}
# Compute distances between each observation and each mean
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km <- cbind(df, d1, d2)
df.km %>%
  kable("html", escape=F) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:5, border_right=TRUE, width="1cm") %>%
  column_spec(4:5, color="#CA6627") 
```

]]]
.column[.pad50px[.content[


]]]

---
class: split-50 
layout: false
count: false

.column[.pad10px[.content[

Select $k=2$, and set initial seed means <br>
$\bar{x}_1=$ (`r xb[1,2:3]`) ,
$\bar{x}_2=$ (`r xb[2,2:3]`) <br>
Compute distances $(d_1, d_2)$ between each observation and each mean.

```{r}
df.km %>%
  kable("html", escape=F) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:5, border_right=TRUE, width="1cm") %>%
  column_spec(4:5, color="#CA6627") 
```

]]]
.column[.pad50px[.content[

Assign the cluster membership

```{r}
df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Assign the cluster membership

```{r}
df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---
class: split-50 
layout: false

.column[.pad10px[.content[

Recompute means, and re-assign the cluster membership

```{r}
xb <- df.km %>%
  group_by(cl) %>%
  summarise(x1=mean(x1), x2=mean(x2))
xb1 <- data.frame(x1=xb$x1[1], x2=xb$x2[1])
xb2 <- data.frame(x1=xb$x1[2], x2=xb$x2[2])
```

$\bar{x}_1=$ (`r round(xb[1,-1], 0)`) ,
$\bar{x}_2=$ (`r round(xb[2,-1], 0)`) <br>

```{r}
d1 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[1,2:3])^2)),1))
d2 <- apply(df[,2:3], 1, function(x) round(sqrt(sum((x-xb[2,2:3])^2)),1))
df.km$d1 <- round(d1, 1)
df.km$d2 <- round(d2, 1)

df.km$cl <- ifelse(d1 < d2, 1, 2)
df.km$cl <- factor(df.km$cl)
kable(df.km) %>%
  kable_styling("striped", position = "center", 
                font_size=24) %>% 
  row_spec(0, color = "white", background = "#3F9F7A") %>%
  column_spec(1:6, border_right=TRUE, width="1cm") %>%
  column_spec(4:6, color="#CA6627")

```
]]]
.column[.pad50px[.content[

```{r out.width="100%", fig.width=4, fig.height=4}
mn <- data.frame(cl=xb$cl, lbl=c("m1", "m2"), 
                 x1=xb$x1, x2=xb$x2)
ggplot() + 
  geom_text(data=df.km, aes(x=x1, y=x2, label=lbl, color=cl)) + 
  geom_point(data=mn, aes(x=x1, y=x2, color=cl), 
             shape=3, size=3) + 
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() +
  theme(aspect.ratio=1, legend.position="None") 
```
]]]

---

class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- .orange[k-means]
    - Example

]]

.column[.top50px[

```{r out.width="80%", fig.width=4, fig.height=4}
ggplot(data=flea) + geom_point(aes(x=tars1, y=aede1)) + theme(aspect.ratio=1) + xlab("") + ylab("")
```


]]


---
class: split-50 
layout: false


.column[.pad50px[.content[

$k=2$

```{r  out.width="100%", fig.width=4, fig.height=4}
set.seed(31)
flea$km2 <- kmeans(scale(flea[,c(1,4)]), 2, nstart=5)$cluster
flea$km3 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=5)$cluster
flea$km4 <- kmeans(scale(flea[,c(1,4)]), 4, nstart=5)$cluster
flea$km5 <- kmeans(scale(flea[,c(1,4)]), 5, nstart=5)$cluster
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km2),
                 shape=factor(km2))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]
.column[.pad50px[.content[

$k=3$

```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km3),
                 shape=factor(km3))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]

---
class: split-50 
layout: false


.column[.pad50px[.content[

$k=4$

```{r  out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km4),
                 shape=factor(km4))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]
.column[.pad50px[.content[

$k=5$

```{r out.width="100%", fig.width=4, fig.height=4}
ggplot(data=flea) + 
  geom_point(aes(x=tars1, y=aede1, colour=factor(km5),
                 shape=factor(km5))) +
  scale_colour_brewer("", palette="Dark2") + 
  theme(aspect.ratio=1, legend.position = "none") + 
  xlab("") + ylab("")
```
]]]

---
class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- [k-means](#4)
- .orange[Choosing k]

]]
.column[.pad50px[

.boxshadow[Cluster statistics]

- .orange[WBRatio]: average within/average between want it to be low, but always drops for each additional cluster so look for large drops
- .orange[Hubert Gamma]: (s+ - s-)/(s+ + s-) where $s+=$sum of number of within $<$ between, $s-=$ sum of number within $>$ between, want this to be high
- .orange[Dunn]: smallest distance between points from different clusters/maximum distance of points within any cluster, want this to be high
- .orange[Calinski-Harabasz Index]: $\frac{\sum_{i=1}^p B_{ii}/(k-1)}{\sum_{i=1}^p W_{ii}/(n-k)}$ want this to be high


]]
---

class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- [k-means](#4)
- .orange[Choosing k]

]]

.column[.top50px[
```{r out.width="100%", fig.width=8, fig.height=6}
library(fpc)
set.seed(31)
f.km <- NULL; f.km.stats <- NULL
for (i in 2:10) {
  cl <- kmeans(scale(flea[,c(1,4)]), i, nstart=5)$cluster
  x <- cluster.stats(dist(scale(flea[,c(1,4)])), cl)
  f.km <- cbind(f.km, cl)
  f.km.stats <- rbind(f.km.stats, c(x$within.cluster.ss, x$wb.ratio, x$ch,
                                    x$pearsongamma, x$dunn, x$dunn2))
}
colnames(f.km.stats) <- c("within.cluster.ss","wb.ratio", "ch", "pearsongamma", "dunn", "dunn2")
f.km.stats <- data.frame(f.km.stats)
f.km.stats$cl <- 2:10
f.km.stats.m <- f.km.stats %>% 
  gather(stat, value, -cl)
ggplot(data=f.km.stats.m) + 
  geom_line(aes(x=cl, y=value)) + xlab("# clusters") + ylab("") +
  facet_wrap(~stat, ncol=3, scales = "free_y") + 
  theme_bw()
```

]]
---
class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- [k-means](#4)
- [Choosing k](#17)
- .orange[k-means caveats]
]]
.column[.pad50px[

.boxshadow[Effect of seed]

- The k-means algorithm can yield quite different results depending on the initial seed.
- Example runs used 5 random starts, and used the `within.cluster.ss` metric to decide on the best solution.

```{r out.width="100%", fig.width=9, fig.height=3}
set.seed(20190513)
flea$cl1 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl2 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl3 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl4 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl5 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
flea$cl6 <- kmeans(scale(flea[,c(1,4)]), 3, nstart=1)$cluster
p1 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl1))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
p2 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl2))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
p3 <- ggplot(data=flea, aes(x=tars1, y=aede1, 
                            colour=factor(cl5))) + 
  geom_point() +
  scale_colour_brewer("", palette="Dark2") +
  xlab("") + ylab("") + theme_bw() + 
  theme(aspect.ratio=1, legend.position="none") 
grid.arrange(p1, p2, p3, ncol=3)
```

]]

---
class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- [k-means](#4)
- [Choosing k](#17)
- [k-means caveats](#19)
- .orange[Interpoint distance measures]
    - Euclidean

]]
.column[.pad50px[

- Cluster analysis depends on the interpoint distances, points close together should be grouped together
- Euclidean distance was used for the example. Let $A=(x_{a1}, x_{a2}, ..., x_{ap}), B=(x_{b1}, x_{b2}, ..., x_{bp})$

\begin{align*}
d_{EUC}(A, B) &= \sqrt{\sum_{j=1}^p (x_{aj}-x_{bj})^2} &\\
&= ((X_A-X_B)^T (X_A-X_B))&
\end{align*}

]]

---
class: split-50
layout: false

.column[.pad10px[

.boxshadow[Other distance metrics]

- Mahalanobis (or statistical) distance

$$\sqrt{((X_A-X_B)^TS^{-1} (X_A-X_B))}$$

- Manhattan: 

$$\sum_{j=1}^p|(X_{aj}-X_{bj})|$$

- Minkowski: 

$$(\sum_{j=1}^p|(X_{aj}-X_{bj})|^m)^{1/m}$$
]]
.column[.pad10px[

.boxshadow[Distances for count data]

- Canberra: 

$$\frac{1}{n_z}\sum_{j=1}^p\frac{X_{aj}-X_{bj}}{X_{aj}+X_{bj}}$$

- Bray-Curtis: 

$$\frac{\sum_{j=1}^p|X_{aj}-X_{bj}|}{\sum_{j=1}^p(X_{aj}+X_{bj})}$$

]]
---
class: split-30
layout: false

.column[.pad10px[
## Outline

- [Cluster analysis](#2)
- [k-means](#4)
- [Choosing k](#17)
- [k-means caveats](#19)
- .orange[Interpoint distance measures]
    - Euclidean
    - Rules

]]
.column[.pad50px[
.boxshadow[Rules for any metric to be a distance]

1. $d(A, B) \geq 0$
2. $d(A, A) = 0$
3. $d(A, B) = d(B, A)$
4. Metric dissimilarity satisfies 
$d(A, B) \geq d(A, C) + d(C, B)$, and an ultrametric dissimilarity satisfies
$d(A, B) \geq max\{d(A, C), d(C, B)\}$

]]
---

layout: false
# `r set.seed(2019); emo::ji("technologist")` Made by a human with a computer

### Slides at [https://monba.dicook.org](https://monba.dicook.org).
### Code and data at [https://github.com/dicook/Business_Analytics](https://github.com/dicook/Business_Analytics).
<br>

### Created using [R Markdown](https://rmarkdown.rstudio.com) with flair by [**xaringan**](https://github.com/yihui/xaringan), and [**kunoichi** (female ninja) style](https://github.com/emitanaka/ninja-theme).

<br> 
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
