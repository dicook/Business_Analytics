---
title: "ETC3250 Assignment 2"
date: "SOLUTION"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE)
```

## Exercises

1. This question is about the normal distribution, and how it relates to the classification rule provided by linear discriminant analysis.

a. (1)Write down the density function for a bivariate normal distribution ($p=2$), with mean $\mu_k$ and variance $\Sigma$. 

$$f(x) = \frac{1}{2\pi|\Sigma|}\exp\{-\frac{1}{2}(x-\mu)'\Sigma^{-1}(x-\mu)\}$$    
where $x=(x_1, x_2)$, $\mu=(\mu_1, \mu_2)$, $\Sigma=\left[ \begin{array}{cc} \sigma_1^2 & \rho\sigma_1\sigma_2 \\ \rho\sigma_1\sigma_2 & \sigma_2^2 \end{array} \right]$

b. (2)Show that the linear discriminant rule for two groups ($K=2$), $\pi_1=\pi_2$ and

$$\Sigma_1=\Sigma_2 = \Sigma = \left[\begin{array}{cc} \sigma_1^2 & \rho\sigma_1\sigma_2 \\ \rho\sigma_1\sigma_2 & \sigma_2^2 \end{array}\right]$$ 
where $\rho$ is the population correlation between the two variables, and $\sigma_1, \sigma_2$ are the population standard deviations of the two variables, respectively, is equal to:
*Assign a new observation $x_0$ to group 1 if*
$$x_0'\Sigma^{-1}(\mu_1-\mu_2) > \frac{1}{2}(\mu_1 + \mu_2)'\Sigma^{-1}(\mu_1-\mu_2)$$
**The rule is to assign observation to the group with the highest probability, so work from the density functions for the tewo groups. Let **

$x=(x_1, x_2)$, $\mu_1=(\mu_{11}, \mu_{12})$, $\mu_2=(\mu_{21}, \mu_{22})$ **then**

$$\frac{1}{2\pi|\Sigma|}\exp\{-\frac{1}{2}(x-\mu_1)'\Sigma^{-1}(x-\mu_1)\}>\frac{1}{2\pi|\Sigma|}\exp\{-\frac{1}{2}(x-\mu_2)'\Sigma^{-1}(x-\mu_2)\}$$  

$$\leadsto ~~~ (x-\mu_1)'\Sigma^{-1}(x-\mu_1) > (x-\mu_2)'\Sigma^{-1}(x-\mu_2)$$
$$\leadsto  ~~~~~~~~~~~~~~~ x'\Sigma^{-1}x -x'\Sigma^{-1}\mu_1 - \mu_1'\Sigma^{-1}x+\mu_1'\Sigma^{-1}\mu_1 > x'\Sigma^{-1}x -x'\Sigma^{-1}\mu_2 - \mu_2'\Sigma^{-1}x+\mu_2'\Sigma^{-1}\mu_2$$
$$\leadsto ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-x'\Sigma^{-1}\mu_1 - \mu_1'\Sigma^{-1}x+\mu_1'\Sigma^{-1}\mu_1> -x'\Sigma^{-1}\mu_2 - \mu_2'\Sigma^{-1}x+\mu_2'\Sigma^{-1}\mu_2 $$
$$\leadsto ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~x'\Sigma^{-1}\mu_1 +x'\Sigma^{-1}\mu_2 + \mu_1'\Sigma^{-1}x + \mu_2'\Sigma^{-1}x >  - \mu_1'\Sigma^{-1}\mu_1 + \mu_2'\Sigma^{-1}\mu_2 $$
$$\leadsto ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~2x'\Sigma^{-1}(\mu_1-\mu_2) > (\mu_1+\mu_2)'\Sigma^{-1}(\mu_1-\mu_2)$$
$$\leadsto ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~x'\Sigma^{-1}(\mu_1-\mu_2) > \frac{1}{2}(\mu_1+\mu_2)'\Sigma^{-1}(\mu_1-\mu_2)$$
c. (2)By generating a grid of values, draw the boundary between two groups, in the 2D space. Use these values for $\mu_1, \mu_2$ and $\sigma$.
$$\mu_1 = \left[\begin{array}{r} -2 \\ 2 \end{array}\right], ~~~\mu_2 = \left[\begin{array}{r} 2 \\ -2 \end{array}\right]$$
$$\Sigma = \left[\begin{array}{rr} 4 & 3 \\ 3 & 5 \end{array}\right]$$
```{r}
library(tidyverse)
x1 <- seq(-10, 10, 0.5)
x2 <- seq(-10, 10, 0.5)
grid <- expand.grid(x1, x2)
library(mvtnorm)
y1 <- dmvnorm(grid, mean=c(-2,2), sigma=matrix(c(4, 3, 3, 5), ncol=2, byrow=T))
y2 <- dmvnorm(grid, mean=c(2,-2), sigma=matrix(c(4, 3, 3, 5), ncol=2, byrow=T))
grid$y1 <- y1
grid$y2 <- y2
grid$cl <- ifelse(grid$y1>grid$y2, 1, 2)
ggplot(grid, aes(x=Var1, y=Var2, colour=factor(cl))) + geom_point() +
  scale_colour_brewer(palette="Dark2") + 
  geom_abline(intercept=0, slope = -0.875)
```

d. (2)Write down the rule using these parameter values, and sketch the line corresponding to the 1D discriminant space on the previous plot.

**Slope of the line corresponding to the discriminant space is given by** $\Sigma^{-1}(\mu_1-\mu_2)$. 

$$\Sigma^{-1}(\mu_1-\mu_2) = 1/11\left[ \begin{array}{cc} 5 & -3 \\ -3 & 4 \end{array}\right] \left[\begin{array}{c} 4\\ -4 \end{array}\right] $$
**slope = -7/8. And run the line through (0,0) to fit into the plot above.**

**Rule is** *Assign x to class 2 if* $8/11x_1-7/11x_2>0$.

2. This question is about dimension reduction using PCA. We will use data from the world bank, on development indicators for 264 countries. Go to this site  https://databank.worldbank.org/data/source/world-development-indicators/preview/on# to extract a copy of the data yourself. You should select all the countries that they have available, and just year 2017. There are some countries that are not countries, that you should exclude: "Upper middle income", "Pre-demographic dividend", "Post-demographic dividend", "Other small states", "OECD members", "Not classified", "Middle income", "Lower middle income", "Low income", "Low & middle income", "Least developed countries", "UN classification", "Late-demographic dividend", "IDA & IBRD total", "IDA blend", "IDA only", "IDA total", "High income", "Heavily indebted poor countries (HIPC)", "Fragile and conflict affected situations". 

Use the default set of variables that are chosen: 

```{r}
library(readxl)
library(tidyverse)
WDI <- read_xlsx("data/Data_Extract_From_World_Development_Indicators.xlsx", na="..", n_max=14466)
exclude <- c("Upper middle income","Pre-demographic dividend", "Post-demographic dividend", "Other small states", "OECD members", "Not classified", "Middle income", "Lower middle income", "Low income", "Low & middle income", "Least developed countries: UN classification", "Late-demographic dividend", "IBRD only", "IDA & IBRD total", "IDA blend", "IDA only", "IDA total", "High income", "Heavily indebted poor countries (HIPC)", "Fragile and conflict affected situations", "Early-demographic dividend", "Data from database: World Development Indicators", "East Asia & Pacific (excluding high income)", "East Asia & Pacific (IDA & IBRD countries)","Euro area","Europe & Central Asia","Europe & Central Asia (excluding high income)", "Europe & Central Asia (IDA & IBRD countries)","European Union", "Latin America & Caribbean", "Latin America & Caribbean (excluding high income)", "Latin America & Caribbean (excluding high income)", "Latin America & the Caribbean (IDA & IBRD countries)", "Middle East & North Africa", "Middle East & North Africa (excluding high income)", "Middle East & North Africa (IDA & IBRD countries)", "South Asia", "South Asia (IDA & IBRD)", "Sub-Saharan Africa", "Sub-Saharan Africa (excluding high income)", "Sub-Saharan Africa (IDA & IBRD countries)")
WDI <- WDI %>% filter(!(`Country Name` %in% exclude))
#WDI %>% count(`Series Name`) %>% print(n=60)
#WDI %>% count(`Country Name`) %>% print(n=300)
```

You will need to do some cleaning on the data. 

i. Remove the two lines which are missing on the `Series Name`, and rename `2017 [YR2017]` to "value".
ii. Make a look up dictionary mapping `Series Code` to `Series Name`, so that we can do the analysis with the code (shorter), but refer back to the name as needed.
iii. Spread the data into wide form, so that you have variables `Country Name`, `Country Code`, and the 55 `Series Name` variables as columns.
iv. Using the `naniar` package make a missingness heatmap of the data
v. Remove any variable that is missing for more than 100 countries. Then, remove any countries that have missing on more than 2 variables.
vi. Use $k$ nearest neighbours imputation to fill in the missings.
 
```{r eval=FALSE}
# This is the code to install the impute package with a knn imputation fn
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("impute", version = "3.8")
```

```{r}
# Remove rows with missings and rename measured variable to value
WDI <- WDI %>% filter(!is.na(`Series Name`)) %>%
  rename(value = `2017 [YR2017]`)
# Create lookup dictionary
WDI_names <- WDI %>% 
  select(`Series Code`, `Series Name`) %>%
  distinct()
# Make wide form to inspect missing data
library(naniar)
library(impute)
WDI_wide <- WDI %>% 
  select(-`Series Name`) %>%
  spread(`Series Code`, value)
vis_miss(WDI_wide, sort_miss=TRUE, cluster=TRUE)
# Remove variables and countries with too many missings
nvmiss <- WDI %>% filter(is.na(value)) %>% count(`Series Code`, sort=TRUE) %>%
  filter(n > 100) %>% summarise(nvmiss=nrow(.))
WDI_varmiss <- WDI %>% filter(is.na(value)) %>% count(`Series Code`, sort=TRUE) %>%
  filter(n <= 100) # Missing on 2/3 countries removed
WDI_nomiss <- WDI %>% filter(`Series Code` %in% WDI_varmiss$`Series Code`) # Down to 32 variables
ncntmiss <- WDI_nomiss %>% filter(is.na(value)) %>% count(`Country Code`, sort=TRUE) %>% filter(n>=3)
WDI_cntmiss <- WDI_nomiss %>% filter(is.na(value)) %>% count(`Country Code`, sort=TRUE) %>% filter(n<3) # Keep countries with only two missings
WDI_nomiss <- WDI_nomiss %>% filter(`Country Code` %in% WDI_cntmiss$`Country Code`)
# Set up for knn, and impute missings
WDI_nomiss_wide <- WDI_nomiss %>% select(-`Series Name`) %>% 
  spread(`Series Code`, value)
WDI_impute <- impute.knn(as.matrix(WDI_nomiss_wide[,-c(1,2)]))$data
WDI_nomiss_wide[,3:34] <- WDI_impute
```


a. (1)How many countries are in the full data set? How many variables? **I have 244 but I am happy to be a bit flexible here, because there a lot of aggregated regions to notice ans remove.**
b. (1)How many variables are missing on more than 100 countries?**I get 23**
c. (1)How many countries have missing values on more than 2 variables, after the variables in b. have been removed?**I get 99 countries**
d. (1)Compute a principal component analysis for the cleaned and imputed data matrix. Tabulate the proportion of variation explained up to 8 PCs. 
```{r}
library(kableExtra)
WDI_pca <- prcomp(WDI_nomiss_wide[,3:34], retx=TRUE, center=TRUE, scale=TRUE)
WDI_pca_var <- tibble(n=1:length(WDI_pca$sdev), evl=WDI_pca$sdev^2) %>% 
  mutate(p=evl/sum(evl))
kable(WDI_pca_var[1:8,], digits=2, align="r") %>% kable_styling()
```
e. (2)Make a scree plot. How many principal components would be suggested? What proportion of variation would be explained by your choice? Please explain your thinking and decisions.

```{r}
ggplot(WDI_pca_var[1:10,], aes(x=n, y=evl)) + geom_line() +
  xlab("Number of PCs") + ylab("Eigenvalue") + ylim(c(0,8))
```

**Three PCs would be suggested by the scree plot, and this would explain 48% of the variation.**

f. (2)Make a biplot of the first two principal components, and explain the contributions of the variables, and similarity of the variables.

```{r fig.width=10, fig.height=4}
library(gridExtra)
library(ggrepel)
WDI_pca_pcs <- as_tibble(WDI_pca$x[,1:3]) %>%
  mutate(cnt=WDI_nomiss_wide$`Country Code`, 
         name=WDI_nomiss_wide$`Country Name`)
WDI_pca_evc <- as_tibble(WDI_pca$rotation[,1:3]) %>% 
  mutate(origin=rep(0, 32), variable=as.character(1:32),
         varname=rownames(WDI_pca$rotation)) %>%
  mutate(PC1s = PC1*(WDI_pca_var$evl[1]*2), 
         PC2s = PC2*(WDI_pca_var$evl[2]*2),
         PC3s = PC3*(WDI_pca_var$evl[3]*2))
p1 <- ggplot() + 
  geom_segment(data=WDI_pca_evc, aes(x=origin, xend=PC1s, y=origin, yend=PC2s), colour="red") +
  geom_text(data=WDI_pca_evc, aes(x=PC1s, y=PC2s, label=variable), colour="red") +
  geom_point(data=WDI_pca_pcs, aes(x=PC1, y=PC2)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC1)>4), aes(x=PC1, y=PC2, label=cnt)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC2)>5), aes(x=PC1, y=PC2, label=cnt)) +
  xlab("PC1") + ylab("PC2") + xlim(c(-6, 10)) + ylim(c(-6, 17)) +
  theme(aspect.ratio=1)
p2 <- ggplot() + 
  geom_segment(data=WDI_pca_evc, aes(x=origin, xend=PC1s, y=origin, yend=PC3s), colour="red") +
  geom_text(data=WDI_pca_evc, aes(x=PC1s, y=PC3s, label=variable), colour="red") +
  geom_point(data=WDI_pca_pcs, aes(x=PC1, y=PC3)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC1)>4), aes(x=PC1, y=PC3, label=cnt)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC3)>2.2), aes(x=PC1, y=PC3, label=cnt)) +
  xlab("PC1") + ylab("PC3") + xlim(c(-6, 10)) + ylim(c(-6, 5)) +
  theme(aspect.ratio=1)
p3 <- ggplot() + 
  geom_segment(data=WDI_pca_evc, aes(x=origin, xend=PC2s, y=origin, yend=PC3s), colour="red") +
  geom_text(data=WDI_pca_evc, aes(x=PC2s, y=PC3s, label=variable), colour="red") +
  geom_point(data=WDI_pca_pcs, aes(x=PC2, y=PC3)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC2)>5), aes(x=PC2, y=PC3, label=cnt)) +
  geom_text_repel(data=filter(WDI_pca_pcs, abs(PC3)>2.2), aes(x=PC2, y=PC3, label=cnt)) +
  xlab("PC2") + ylab("PC3") + xlim(c(-6, 17)) + ylim(c(-6, 5)) +
  theme(aspect.ratio=1)
grid.arrange(p1, p2, p3, ncol=3)
```
**The PCs are a combination of many of the variables. It is difficult to compare and contrast from the biplot. China is clearly an outlier in the first three PCs.**

g. (2)Examine the largest coefficients for the first three principal components. Explain and interpret the first three principal components. 

```{r}
#WDI_pca_evc %>% select(variable, varname, PC1) %>% arrange(desc(PC1)) %>% print(n=32)
WDI_pca_evc %>% 
  select(variable, varname, PC1) %>% 
  filter(abs(PC1)>0.24) %>% 
  left_join(WDI_names, by=c("varname"="Series Code")) %>%
  arrange(PC1)
#WDI_pca_evc %>% select(variable, varname, PC2) %>% arrange(desc(PC2)) %>% print(n=32)
WDI_pca_evc %>% 
  select(variable, varname, PC2) %>% 
  filter(abs(PC2)>0.24) %>% 
  left_join(WDI_names, by=c("varname"="Series Code")) %>%
  arrange(PC2)
#WDI_pca_evc %>% select(variable, varname, PC3) %>% arrange(desc(PC3)) %>% print(n=32)
WDI_pca_evc %>% 
  select(variable, varname, PC3) %>% 
  filter(abs(PC3)>0.24) %>% 
  left_join(WDI_names, by=c("varname"="Series Code")) %>%
  arrange(PC3)
```

**I chose an arbitrary cut off of 0.24 to indicate the largest coefficients. Technically, significant coefficients would be roughly anything larger than 1/p, but this would generate too many variables to examine.**  

**PC1 may be an indicator for development, because it contrasts mortality, rural industry, population, against income. High values indicate high development (eg China, Germany, Netherlands), and low values less development (eg Sierra Leone, Sudan, Chad).**

**PC2 and PC3 are harder to explain. PC2 is a combination of land area, population, and GDP indicators.It basically indicates China is different from all other countries. PC3 is a contrast of trade, industry and military against GDP growth and rural. On one extreme is Kuwait, Congo, Russia and Iraq against Sierra Leone, Comoros, Liberia, Guinea-Bissau.**

h. (2)Several countries stand out as outliers on the biplots. Examine the principal component scores for the first three principal components. Identify the countries that are at the extremes of each, and explain what their characteristics are. Make a plot to support your arguments.
    
```{r fig.width=10, fig.height=3}
p1 <- ggplot(WDI_nomiss_wide, aes(x=SH.DYN.MORT)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("Germany", "Chad")), aes(xintercept=SH.DYN.MORT, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC1 extremes")
p2 <- ggplot(WDI_nomiss_wide, aes(x=NY.GNP.PCAP.PP.CD)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("Germany", "Chad")), aes(xintercept=NY.GNP.PCAP.PP.CD, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC1 extremes")
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(WDI_nomiss_wide, aes(x=SP.POP.TOTL)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("China", "Luxembourg")), aes(xintercept=SP.POP.TOTL, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC2 extremes")
p2 <- ggplot(WDI_nomiss_wide, aes(x=NY.GNP.ATLS.CD)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("China", "Luxembourg")), aes(xintercept=NY.GNP.ATLS.CD, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC2 extremes")
grid.arrange(p1, p2, ncol=2)
p1 <- ggplot(WDI_nomiss_wide, aes(x=NV.IND.TOTL.ZS)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("Sierra Leone", "Congo, Rep.")), aes(xintercept=NV.IND.TOTL.ZS, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC3 extremes")
p2 <- ggplot(WDI_nomiss_wide, aes(x=NV.AGR.TOTL.ZS)) + geom_density(fill="black", alpha=0.3) +
  geom_vline(data=filter(WDI_nomiss_wide, `Country Name` %in% c("Sierra Leone", "Congo, Rep.")), aes(xintercept=NV.AGR.TOTL.ZS, colour=`Country Name`)) +
  scale_colour_brewer("", palette="Dark2") + ggtitle("PC3 extremes")
grid.arrange(p1, p2, ncol=2)
```

**Chad and Germany are on opposite ends of PC1. Looking at two key variables, mortality and average income, the vast difference between the two countries can be seen: Germany has high income and low mortality, and Chad is the opposite.**

**On PC2 Luxembourg has low scores, and China has high scores. China is a heavily populated, large country with a high GNP, and the reverse is true for Luxembourg.** 

**Congo has low scores on PC3 and Sierra Leone has high scores. Congo has a large proportion of GDP due to industry, and low due to agriculture, and looks to be an African powerhouse. This is a bit surprising, but reading about Congo (on wikipedia) indicates that it is about to boom as one of the few cobalt producers in the world, essential for lithium batteries in electric vehicles. They say it is the "Saudia Arabia of the electric vehicle age". Sierra Leone is relatively non-industrial, and primarily agricultural.**

i. (2)Use bootstrap, resampling the countries to produce 95% confidence intervals for the coefficients on PC1. Revise your interpretation of PC1 based on significance of the coefficients. 
    
```{r}
library(boot)
library(forcats)
compute_PC <- function(data, index, k=1, anchor=1) {
  pc <- prcomp(data[index,], center=TRUE, scale=TRUE)$rotation[,k]
  if (sign(pc[anchor]) > 0)
    pc <- -pc
  return(pc)
}
# Make sure the first coefficient of the PC is positive.
#x <- WDI_nomiss_wide %>%
#  filter(`Country Name` != "China")
PC1_boot <- boot(data=WDI_nomiss_wide[,3:34], compute_PC, anchor=25, R=1000)
colnames(PC1_boot$t) <- colnames(WDI_nomiss_wide[,3:34])
PC1_boot_t0 <- tibble(var=factor(names(PC1_boot$t0), levels=names(PC1_boot$t0)), t0=PC1_boot$t0)
PC1_boot_ci <- as_tibble(PC1_boot$t) %>%
  gather(var, coef) %>% 
  mutate(var = factor(var, levels=levels(PC1_boot_t0$var))) %>%
  group_by(var) %>%
  summarise(q2.5 = quantile(coef, 0.025), 
            q5 = median(coef),
            q97.5 = quantile(coef, 0.975)) %>%
  left_join(PC1_boot_t0) 
#PC1_boot_ci %>% arrange(t0) %>% print(n=32)
ggplot(PC1_boot_ci, aes(x=fct_reorder(var, q2.5), y=t0)) + 
  geom_hline(yintercept=0, colour="white", size=2) +
  geom_point() + 
  geom_errorbar(aes(ymin=q2.5, ymax=q97.5)) +
  xlab("") + ylab("Coeffient") + 
  coord_flip()
PC2_boot <- boot(data=WDI_nomiss_wide[,3:34], compute_PC, k=2,  anchor=29, R=1000)
colnames(PC2_boot$t) <- colnames(WDI_nomiss_wide[,3:34])
```

```{r eval=FALSE}
PC2_boot_t0 <- tibble(var=factor(names(PC2_boot$t0), levels=names(PC2_boot$t0)), t0=PC2_boot$t0)
PC2_boot_ci <- as_tibble(PC2_boot$t) %>%
  gather(var, coef) %>% 
  mutate(var = factor(var, levels=levels(PC2_boot_t0$var))) %>%
  group_by(var) %>%
  summarise(q2.5 = quantile(coef, 0.025), 
            q5 = median(coef),
            q97.5 = quantile(coef, 0.975)) %>%
  left_join(PC2_boot_t0) 
ggplot(PC2_boot_ci, aes(x=fct_reorder(var, q2.5), y=t0)) + 
  geom_hline(yintercept=0, colour="white", size=2) +
  geom_point() + 
  geom_errorbar(aes(ymin=q2.5, ymax=q97.5)) +
  xlab("") + ylab("Coeffient") + 
  coord_flip()
#PC2_boot_ci %>% arrange(t0) %>% print(n=32)
PC3_boot <- boot(data=WDI_nomiss_wide[,3:34], compute_PC, k=3, anchor=16, R=1000)
colnames(PC3_boot$t) <- colnames(WDI_nomiss_wide[,3:34])
PC3_boot_t0 <- tibble(var=factor(names(PC3_boot$t0), levels=names(PC3_boot$t0)), t0=PC3_boot$t0)
PC3_boot_ci <- as_tibble(PC3_boot$t) %>%
  gather(var, coef) %>% 
  mutate(var = factor(var, levels=levels(PC3_boot_t0$var))) %>%
  group_by(var) %>%
  summarise(q2.5 = quantile(coef, 0.025), 
            q5 = median(coef),
            q97.5 = quantile(coef, 0.975)) %>%
  left_join(PC3_boot_t0) 
#PC3_boot_ci %>% arrange(t0) %>% print(n=32)
ggplot(PC3_boot_ci, aes(x=fct_reorder(var, q2.5), y=t0)) + 
  geom_hline(yintercept=0, colour="white", size=2) +
  geom_point() + 
  geom_errorbar(aes(ymin=q2.5, ymax=q97.5)) +
  xlab("") + ylab("Coeffient") + 
  coord_flip()
```

**The direction of the eigenvector needs to be fixed to one of the larger variables. I've used SH.DYN.MORT. Several of the variables have significant coefficients, for PC1. PC1 would still be interpreted similarly, it is basically financially wealthy, (plus good statistical capacity, and imunization program), against population growth, high mortality and prevalence of AIDS.**

(*Interestingly, the coefficients are more stable in the bootstrapping if China is removed, because it has a high influence on the PCA. Also PC3 would be dropped with the bootstrap analysis because no variable has a coefficient substantially different from 0.*)

j. (1)True or false. *Principal* has the same meaning as *principle*. **FALSE**