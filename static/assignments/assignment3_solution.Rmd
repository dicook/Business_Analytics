---
title: "ETC3250 Assignment 3"
date: "SOLUTION"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  eval = FALSE,
  message = FALSE,
  warning = FALSE)
```

## Exercises

1. *About the data*: The chocolates data was compiled by students in a previous class of Prof Cook, by collecting nutrition information on the chocolates as listed on their internet sites. All numbers were normalised to be equivalent to a 100g serving. Units of measurement are listed in the variable name.
```{r eval=FALSE}
library(tidyverse)
choc <- read_csv("data/chocolates.csv")
choc <- choc %>% mutate(Type = as.factor(Type))
```
a. (2)Use the tour, with type of chocolate mapped to colour, and write a paragraph on whether the two types of chocolate differ on the nutritional variables. 
```{r eval=FALSE}
library(tourr)
quartz()
library(RColorBrewer)
pal <- brewer.pal(3, "Dark2")
col <- pal[as.numeric(choc$Type)]
animate_xy(choc[,5:14], axes="bottomleft", col=col)
```

**The two groups are different from each other, but they are not spearated groups. There are some chocolates of each type that are more similar to the other type on these nutritional charateristics.**

b. (2)Make a parallel coordinate plot of the chocolates, coloured by type, with the variables sorted by how well they separate the groups. Maybe the "uniminmax" scaling might work best for this data. Write a paragraph explaining how the types of chocolates differ in nutritional characteristics.
```{r}
library(GGally)
library(plotly)
p <- ggparcoord(choc, columns = 5:14, groupColumn = 4, order="anyClass", scale="uniminmax") +
  scale_color_brewer(palette="Dark2") + ylab("") + xlab("")
ggplotly(p)
```

**The trend in lines differs for the two types of chocolates. Milk chocolates tend to have higher values on the variables Na, Chol, Sugars and Carbs, and Dark chocolates tend to have higher values on Fiber, TotFat, CalFat, SatFat. Protein and Calories tend not to be different on chocolate types.**

c. (2)Identify one dark chocolate that is masquerading as dark, that is, nutritionally looks more like a milk chocolate. Explain your answer. 
```{r }
ggplot(choc, aes(x=Na_mg, y=Fiber_g, colour=Type, label=paste(MFR, Name))) + geom_point() +
  scale_color_brewer(palette="Dark2") + theme(aspect.ratio=1)
ggplotly()
```

**Mars Dark chocolate is one that appears to be more nutritionally similar to milk chocolate.**

2. Subset the olive oil data to regions 2, 3 only. 
    a. Fit a linear discriminant analysis model. 
    b. (3)Write down the rule. Make it clear which region is class 1 and class 2 relative to the formula in the notes.
```{r eval=TRUE}
library(tidyverse)
library(MASS)
olive <- read_csv("http://www.ggobi.org/book/data/olive.csv") %>%
  rename(name=X1) %>%
  filter(region != 1)
olive_lda <- lda(region~., data=olive[,-c(1,3)])
olive_lda
as.matrix(olive_lda$means)%*%olive_lda$scaling
apply(as.matrix(olive_lda$means), 2, mean)%*%olive_lda$scaling
```

**Assign a new observation to region 3 if
0.003883828palmitic+0.013671576palmitoleic+
0.017953780stearic+0.003574435oleic-
0.007004066linoleic-0.012046402linolenic-
0.019400750arachidic-0.120815557eicosenoic+28.19615>0**

3. This question is about decision trees. Here is a sample data set to work with:
```
# A tibble: 6 x 2
id    x     class
1    -4     1
2     1     1
3     3     2
4     4     1
5     5     1
6     6     2
7     8     2
```

a. (2)Write down the formulae for the impurity metric, entropy. Show that entropy $plog p$ has its highest value at 0.5. Explain why a value of 0.5 leads to the worst possible split.

$$-plog(p)-(1-p)log(1-p)$$

```{r eval=TRUE}
p <- seq(0.05, 0.95, 0.05)
df <- tibble(p, ent=-p*log(p)-(1-p)*log(1-p))
ggplot(df, aes(p, ent)) + geom_line()
```

**A value of 0.5 corresponds to a group with even number of observations in the subset. Thus, it is a very mixed group, and not pure.**

b. (2)Write an function to compute impurity measure, entropy, for a data partitition. 
    
```{r  eval=TRUE, echo=TRUE}
myentropy <- function(p) {
  if (p>0 && p<1) {
    ent <- -p*log(p)-(1-p)*log(1-p)
  }
  else {
    ent <- 0
  }
  return(ent)
}
# This only works for two classes, one variable
mysplit <- function(x, spl, cl) {
  n <- length(x)
  cl_unique <- unique(cl)
  left <- x[x<spl]
  cl_left <- cl[x<spl]
  n_l <- length(left)
  right <- x[x>=spl]
  cl_right <- cl[x>=spl]
  n_r <- length(right)
  p_l <- length(cl_left[cl_left == cl_unique[1]])/n_l
  p_r <- length(cl_right[cl_right == cl_unique[1]])/n_r
  if (is.na(p_l)) p_l<-0.5
  if (is.na(p_r)) p_r<-0.5
  impurity <- (n_l/n)*myentropy(p_l) + (n_r/n)*myentropy(p_r)
  return(impurity)
}
```

c. (2)Use your function to compute the entropy impurity measure for every possible split of the sample data. 
    
```{r eval=TRUE}
df <- tibble(id=1:7, x=c(-4,1,3,4,5,6,8), class=c(1,1,2,1,1,2,2))
split <- NULL; imp <- NULL;
for (i in 1:(length(df$x)-1)) {
  s <- (df$x[i]+df$x[i+1])/2
  a <- mysplit(df$x, s, df$class)
  split <- c(split, s)
  imp <- c(imp, a)
}
df_impurity <- tibble(split, imp)
df_impurity
```

d. (2)Make a plot of your splits and the impurity measure. Where would the split be made?

```{r eval=TRUE}
ggplot() + geom_line(data=df_impurity, aes(x=split, y=imp)) +
  geom_rug(data=df, aes(x=x, colour=factor(class)), size=3) + 
  geom_vline(xintercept=df_impurity$split, linetype=2) +
  scale_colour_brewer(palette="Dark2") +
  theme(legend.position="none")
```

e. (2)Subset the olive oil data to regions 2, 3 only. Fit a classification tree to this data. Summarise the model fit, by writing out the decision tree.

```{r eval=TRUE}
library(rpart)
olive_rp <- rpart(region~., data=olive[,-c(1,3)])
olive_rp
```
f. (2)Compute entropy impurity measure for all possible splits on linoleic acid. Plot this against the splits. Explain where the best split is.
```{r eval=TRUE}
split <- NULL; imp <- NULL;
ord <- order(olive$linoleic)
x <- olive$linoleic[ord]
cl <- olive$region[ord]
for (i in 1:(length(olive$linoleic)-1)) {
  s <- (x[i]+x[i+1])/2
  a <- mysplit(x, s, cl)
  split <- c(split, s)
  imp <- c(imp, a)
}
olive_impurity <- tibble(split, imp)
ggplot() + geom_line(data=olive_impurity, aes(x=split, y=imp)) +  
  geom_rug(data=olive, aes(x=linoleic, colour=factor(region)), size=1, alpha=0.5) + 
  geom_vline(xintercept=1054, linetype=2) +
  scale_colour_brewer(palette="Dark2") +
  theme(legend.position="none")
```

g. (3)Compute entropy impurity measure for all possible splits on all of the other variables, except for eicosenoic acid. Plot all of these values against the split, all six plots. Are there other possible candidates for splitting, that are almost as good as the one chosen by the tree? Explain yourself.

```{r eval=TRUE}
all <- NULL
for (j in c(4:7,9,10)) { # columns for variables
  x <- as.vector(as.matrix(olive[,j]))
  ord <- order(x)
  x <- x[ord]
  cl <- olive$region[ord]
  split <- NULL; imp <- NULL;
  for (i in 1:(length(x)-1)) {
    s <- (x[i]+x[i+1])/2
    a <- mysplit(x, s, cl)
    split <- c(split, s)
    imp <- c(imp, a)
  }
  impurity <- tibble(split, imp, var=colnames(olive)[j])
  all <- bind_rows(all, impurity)
}
olive_long <- olive %>% 
  dplyr::select(region, palmitic, palmitoleic, stearic, oleic, linolenic, arachidic) %>%
  gather(var, pct, -region) 
ggplot() + geom_line(data=all, aes(x=split, y=imp)) +  
  geom_rug(data=olive_long, aes(x=pct, colour=factor(region)), alpha=0.5) +
  scale_colour_brewer(palette="Dark2") +
  facet_wrap(~var, scales="free_x") +
  ylim(c(0,0.75)) + ylab("entropy") + xlab("") +
  theme(legend.position="none")
```

4. (3)In the simulated data provided, determine how many groups there are, and whether there are any outliers. Explain your answers.

```{r}
# This is the code used to generate the data
library(mvtnorm)
# Cluster 1 has elliptical shape
x <- rmvnorm(500, 
  sigma=matrix(c(1, 0.9, 0.7, 0.9, 1, 0.7, 0.7, 0.7, 1), ncol=3, byrow=T))
# Five outliers added
x <- data.frame(x)
y <- data.frame(X1=runif(5, 1, 2), X2=runif(5, -2, -1), X3=runif(5, -2, -1))
df <- bind_rows(x, y)
# Add two more columns which are simply noise to cluster 1, and outliers
df$X4 <- runif(505, -0.5, 0.5)
df$X5 <- runif(505, -0.5, 0.5)
# Three additional fairly spherical clusters, which are centered at 0 in first three vars
# and at (2,2), (-2, -2) and (3, -2.5) in other two vars
z <- data.frame(X1=runif(200, -0.5, 0.5), X2=runif(200, -0.5, 0.5), 
                X3=runif(200, -0.5, 0.5), X4=rnorm(200, 2, 0.5), X5=rnorm(200, 2, 0.5))
w <- data.frame(X1=runif(100, -0.5, 0.5), X2=runif(100, -0.5, 0.5), 
                X3=runif(100, -0.5, 0.5), X4=rnorm(100, -2, 0.7), X5=rnorm(100, -2, 0.7))
v <- data.frame(X1=runif(120, -0.5, 0.5), X2=runif(120, -0.5, 0.5), 
                X3=runif(120, -0.5, 0.5), X4=rnorm(120, 3, 0.7), X5=rnorm(120, -2.5, 0.7))
df <- bind_rows(df, z, w, v)

quartz()
library(tourr)
animate_xy(x)
animate_xy(df)
library(GGally)
ggparcoord(df, columns=1:5)
ggscatmat(df)
write_csv(df, path="vis_challenge.csv")
```

```{r eval=FALSE}
# Code needed to read and view data
df <- read_csv("vis_challenge.csv")
quartz()
library(tourr)
animate_xy(df)
```

**The simulated data has four clusters, one large elliptical cluster and three relatively smaller. There are also five points which are outliers in the first three variables.**